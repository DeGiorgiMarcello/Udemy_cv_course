{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation and image contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = 'images/cap4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img,title=\"img\",waitKey=True):\n",
    "    cv2.imshow(title,img)\n",
    "    if waitKey:\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contours found:  5\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(path+'shapes2.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#it's better to apply canny before. For example, without Canny the number of contour \n",
    "#would be 1!\n",
    "\n",
    "canny = cv2.Canny(gray,20,200)\n",
    "copy = np.copy(canny)\n",
    "contours, hierarchy = cv2.findContours(copy,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "print(\"Contours found: \",str(len(contours)))\n",
    "#with -1 we draw all the contours\n",
    "cv2.drawContours(img,contours,-1,(0,255,0),3)\n",
    "show_image(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print <b>contours</b> we obtain a list of list. In this case we have 5 contours, so we have 5 lists. Each element in each list is the coordinate of a point belonging to that contour. As parameters in findContours, at the approximation, we can use:\n",
    "    \n",
    "    cv2.CHAIN_APPROX_NONE: we store ALL the the points of a contour\n",
    "    cv2.CHAIN_APPROX_SIMPLE: we store only the important points -> start and ending points\n",
    "\n",
    "Another parameter is the **retrieval mode**:\n",
    "\n",
    "    cv2.RETR_LIST: retrieve all the contours\n",
    "    cv2.RETR_EXTERNAL: retrieve external or outer contours only\n",
    "    ... other retrieval method but these are the most useful\n",
    "If for example we have some holes in the shapes, with RETR_LIST we can retrieve also the contours of the holes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area of shapes\n",
    "\n",
    "To compute the area of the contours we can simply use **cv2.contourArea(contour)**\n",
    "Let's calculate the areas and then sort the contours for increasing ara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas before sorting:  [8511.5, 7404.0, 12975.0, 23456.0, 8874.0]\n",
      "Area after sorting:  [7404.0, 8511.5, 8874.0, 12975.0, 23456.0]\n"
     ]
    }
   ],
   "source": [
    "def get_contour_areas(contours):\n",
    "    areas = []\n",
    "    for contour in contours:\n",
    "        areas.append(cv2.contourArea(contour))\n",
    "    return areas\n",
    "\n",
    "print(\"Areas before sorting: \",get_contour_areas(contours))\n",
    "#let's sort:\n",
    "sorted_contours = sorted(contours,key=cv2.contourArea)\n",
    "print(\"Area after sorting: \",get_contour_areas(sorted_contours))\n",
    "\n",
    "#draw a center:\n",
    "copy = np.copy(img)\n",
    "shape=1\n",
    "for c in sorted_contours:\n",
    "    center = np.mean(c,axis=0)\n",
    "    center =  ((int(center[0,0])-5,int(center[0,1])+10))\n",
    "    cv2.putText(copy,str(shape),center,cv2.FONT_HERSHEY_PLAIN,1,(0,0,255),2)\n",
    "    shape+=1\n",
    "show_image(copy,\"Shapes ordered for area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting left to right\n",
    "The solutions seen so far for calculating the center of the shape is not ideal, by the moment that it depends on the regularity of the shape. For a complex and unregular shape it wont show the center. In order to get the right center we need to use the momentum.\n",
    "In particularly we need to compute the center of mass of the shapes.\n",
    "**cv2.Moments(c)** allows to compute the moments of the shape. In particular:\n",
    "\n",
    "    M['m00'] correspond to the Area\n",
    "    M['m10'] correspond to the moment of inertia wrt x-axis\n",
    "    M['m01'] correspond to the moment of inertia wrt y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path+'shapes2.jpg')\n",
    "copy = np.copy(img)\n",
    "\n",
    "def label_contour_center(image,c):\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    center = (cx,cy)\n",
    "    cv2.circle(copy,center,10,(0,0,255),-1)\n",
    "    return copy,center\n",
    "\n",
    "centers = []\n",
    "for c in contours:\n",
    "    orig,center = label_contour_center(copy,c)\n",
    "    centers.append(center)\n",
    "    \n",
    "show_image(orig)\n",
    "\n",
    "centers_left_to_right = np.sort(centers,axis=0)\n",
    "\n",
    "for (i,c) in enumerate(centers_left_to_right):\n",
    "    center = (c[0],c[1])\n",
    "    cv2.putText(copy,str(i+1),center,cv2.FONT_HERSHEY_PLAIN,3,(255,0,0),2)\n",
    "show_image(copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **cv2.boundingRect(c)** we can have the x,y of the top-left corner, width and heigth of the bounding rectangle that contains the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(copy,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "    \n",
    "show_image(copy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex hull\n",
    "Convex hull is a poligon created using all the extreme contour points of a shape. It represents the tiniest poligon that can contain the shape.\n",
    "Let's take the image of an hand and apply all the necessary to obtain the contour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-0f563e0dae69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcanny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_gray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m170\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_LIST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_NONE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"contours\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(path+'hand.png')\n",
    "copy = np.copy(img)\n",
    "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "canny = cv2.Canny(img_gray,20,170)\n",
    "contours,hierarchy = cv2.findContours(canny,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.drawContours(copy,contours,-1,(0,255,0),3)\n",
    "show_image(copy,\"contours\")\n",
    "\n",
    "#there are some internal contours that we want to discard. Let's sort using area\n",
    "main_contour = sorted(contours,key=cv2.contourArea,reverse=False)[-1]\n",
    "copy2 = np.copy(img)\n",
    "cv2.drawContours(copy2,main_contour,-1,(0,255,0),3)\n",
    "show_image(copy2,\"Main contour\")\n",
    "\n",
    "hull = cv2.convexHull(main_contour)\n",
    "#hull among square brakets because drawContours want a list as parameter\n",
    "cv2.drawContours(copy2,[hull],-1,(0,255,0),2)\n",
    "show_image(copy2,\"Hull\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape matching\n",
    "We have a shape and, in another image, we want to find all the shapes that are similar to the given one, to an arbitrary scale and/or roto-traslation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I don't know why this doesn't work\n",
    "shapes = cv2.imread(path+'shapes3.jpg')\n",
    "target = cv2.imread(path+'target.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "shapes_gray = cv2.cvtColor(shapes,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, th_shapes = cv2.threshold(shapes_gray,127,255,1)\n",
    "ret, th_target = cv2.threshold(target,127,255,1)\n",
    "\n",
    "target_contours,hierarchy = cv2.findContours(th_target,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "shapes_contours,hierarchy = cv2.findContours(th_shapes,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "target_contour = sorted(target_contours,key=cv2.contourArea)[-1]\n",
    "\n",
    "\n",
    "for c in shapes_contours:\n",
    "    match = cv2.matchShapes(target_contour,c,1,0.0)\n",
    "    if match < 0.55:\n",
    "        closest_contour = c\n",
    "    else:\n",
    "        closest_contour = []\n",
    "cv2.drawContours(shapes,closest_contour,-1,(0,255,0),3)\n",
    "show_image(shapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line detection - Hough lines\n",
    "![title](images/cap4/hough_lines.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path+'lines.jpg')\n",
    "img = cv2.resize(img,None,fx=0.5,fy=0.5)\n",
    "copy = np.copy(img)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,70,200)\n",
    "# rho accuracy of 1, theta accuracy of pi/180 (so 1 degree), line threshold of 240 points on a line\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,240)\n",
    "\n",
    "for line in lines:\n",
    "    for rho,theta in line:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0= a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000 *(-b))\n",
    "        y1 = int(y0 + 1000 *(a))\n",
    "        x2 = int(x0 - 1000 *(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(copy,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "show_image(copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Hough lines\n",
    "**lines = cv2.HoughLinesP(binarizedImage,rho accuracy,theta accuracy,threshold,minimum line lenght,max line gap)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = np.copy(img)\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,5,10)\n",
    "\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(copy,(x1,y1),(x2,y2),(0,0,255),3)\n",
    "    \n",
    "show_image(copy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circle Detection \n",
    "**cv2.HoughCircles(image, method, dp, MinDist, param1, param2, minRadius, MaxRadius)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path+'bottle_caps.jpg')\n",
    "img = cv2.resize(img,None,fx=0.5,fy=0.5)\n",
    "blur = cv2.medianBlur(img,5)\n",
    "gray = cv2.cvtColor(blur,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,1.3,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoughCircles gives in output a list of circles composed by 3 elements: **x** and **y** of the **center** and the **radius length** of each circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circles found:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"Circles found: \",len(circles[0]))\n",
    "copy = np.copy(blur)\n",
    "for circle in circles[0,:]:\n",
    "    cv2.circle(copy,(circle[0],circle[1]),circle[2],(0,255,0),2)\n",
    "    cv2.circle(copy,(circle[0],circle[1]),2,(255,0,0),3)\n",
    "show_image(copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob Detection\n",
    "The step for blobs detection are:\n",
    " \n",
    "    1) Create a detector\n",
    "    2) Give the input image\n",
    "    3) Get the Keypoints\n",
    "    4) Draw the keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path+'sunflowers.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img,None,fx=0.5,fy=0.5)\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create() \n",
    "\n",
    "#detect blobs:\n",
    "keypoints = detector.detect(img)\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(img,keypoints,blank,(0,255,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "show_image(blobs,\"Blobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is nothing we can do to modify the numbers of the blobs found. That's because we are using the default consctructor for the simple blob detector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniProject - counting circles and ellipses\n",
    "\n",
    "https://www.learnopencv.com/blob-detection-using-opencv-python-c/\n",
    "\n",
    "This link shows a lot of params we can exploit to obtain a perfect result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path+'blobs.jpg')          \n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "h,w = img.shape[:2]\n",
    "\n",
    "\n",
    "#Set filtering parameters\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.filterByArea = False\n",
    "params.filterByCircularity = False\n",
    "params.filterByInertia = False\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "keyPoints = detector.detect(gray)\n",
    "blank = np.zeros((1,1))\n",
    "copy = np.copy(img)\n",
    "blobs = cv2.drawKeypoints(copy,keyPoints,blank,(0,0,255),cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "text = \"Blobs found: \" + str(len(keyPoints))\n",
    "cv2.putText(blobs,text,(10,h-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "show_image(blobs,\"All Blobs\")\n",
    "\n",
    "\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.filterByArea = False\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.8\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.6\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "keyPoints = detector.detect(gray)\n",
    "copy = np.copy(img)\n",
    "blobs = cv2.drawKeypoints(copy,keyPoints,blank,(0,0,255),cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "text = \"Circles found: \" + str(len(keyPoints))\n",
    "cv2.putText(blobs,text,(10,h-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "show_image(blobs,\"Circles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "\n",
    "\n",
    "def gaussianBlur(img):\n",
    "    sigma = 1\n",
    "    k = 3*sigma\n",
    "    k_size = np.int(np.ceil((2*k+1)**2))\n",
    "    gk = cv2.getGaussianKernel(k_size,sigma)\n",
    "    blurred = cv2.filter2D(img,-1,gk)\n",
    "    blurred = cv2.filter2D(blurred,-1,gk.T)\n",
    "    return blurred\n",
    "\n",
    "def compute_convex_hull(frame):\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray = gaussianBlur(gray)\n",
    "    canny = cv2.Canny(gray,70,160)\n",
    "    _,contours,hierarchy = cv2.findContours(canny,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    main_contour = sorted(contours,key=cv2.contourArea,reverse=False)[-1]\n",
    "    hull = cv2.convexHull(main_contour)\n",
    "    cv2.drawContours(frame,[hull],-1,(0,255,0),2)\n",
    "    return frame\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    hull = compute_convex_hull(frame)\n",
    "    cv2.imshow(\"hull\",hull)\n",
    "    if cv2.waitKey(3) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
